---
layout: seminar_page
n: 234
date: 2025-03-11T19:00:00
title: Enabling and Exploiting High-Speed In-Network Computing
speaker: Dr. Vishal Shrivastav, Assistant Professor, Purdue University
Venue: Online on Zoom
speaker_url: https://web.ics.purdue.edu/~vshriva/
speaker_bio: Vishal Shrivastav is an Assistant Professor in the School of Electrical and Computer Engineering at Purdue University. His research interests are broadly in computer networking and systems, with a focus on programmable and reconfigurable networks, in-network computing, and network hardware design. Vishal received his Ph.D. and M.S. degrees in Computer Science from Cornell University and his undergraduate degree in Computer Science and Engineering from the Indian Institute of Technology, Kharagpur. Vishal is a recipient of a National Science Foundation CAREER Award, a Google Research Scholar Award, a Cisco Research Award, and an Eta Kappa Nu (HKN) Outstanding Professor Award.
recorded_video: ioBRIYOAFP0
img: ''
Topic_abstract: |-
  In-network computing, in which custom computations can be offloaded to network devices, has emerged as a powerful computing paradigm to improve the performance of a wide-range of networked and distributed systems and applications. The key enablers for in-network computing are high-speed and programmable network devices, such as programmable switches and SmartNICs. Unfortunately, existing high-speed, programmable network devices are extremely computationally constrained---first, due to cost and power constraints, these devices have very limited high-speed on-chip memory; and second, in order to ensure line rate packet processing, these devices often have an extremely constrained domain-specific processing architecture. As such, these limitations present a major challenge in realizing the full potential of in-network computing.

  In this talk, I will present two systems that take us a step closer to unlocking the full potential of in-network computing. In the first part of the talk, I will present a system called Seer, that tackles the issue of limited on-chip memory on network devices, by designing an online caching scheme that leverages network delays to achieve near-optimal cache hit ratio for state-intensive network applications. In the second part of the talk, I will present a system called Leo, which presents a highly efficient design for utilizing and multiplexing the limited and constrained compute resources on a programmable switch, to implement ML-based traffic analysis models. Leo thus paves way for, among other things, next-generation network intrusion detection systems that could inspect and analyze every single packet going though the network at multi-Tbps speed, and react to malicious traffic in real time.
slides: ''
zoom_link: https://us06web.zoom.us/j/83388976389?pwd=XcpO3GhLxsR14a7SVbPx33HQQa1jbt.1
---

